{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f47bc4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "with open('data/resume_juanjosecarin.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "ruler = nlp.add_pipe('entity_ruler')\n",
    "with open('data/names.txt', 'r') as f:\n",
    "    names = f.readlines()\n",
    "names = [name.strip() for name in names]\n",
    "\n",
    "with open('data/skills.txt', 'r') as f:\n",
    "    skills = f.readlines()\n",
    "skills = [skill.strip() for skill in skills]\n",
    "\n",
    "with open('data/certifications.txt', 'r') as f:\n",
    "    certifications = f.readlines()\n",
    "certifications = [certi.strip() for certi in certifications]\n",
    "\n",
    "with open('data/education.txt', 'r') as f:\n",
    "    education = f.readlines()\n",
    "education = [edu.strip() for edu in education]\n",
    "\n",
    "with open('data/job_roles.txt', 'r') as f:\n",
    "    job_roles = f.readlines()\n",
    "job_roles = [jr.strip() for jr in job_roles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "439fba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = []\n",
    "for skill in skills:\n",
    "    tokens = skill.split()\n",
    "    pattern = [{\"LOWER\": token.lower()} for token in tokens]\n",
    "    patterns.append({\"label\": \"SKILL\", \"pattern\": pattern})\n",
    "\n",
    "for name in names:    \n",
    "    tokens = name.split()\n",
    "    pattern = [{\"LOWER\": token.lower()} for token in tokens]\n",
    "    patterns.append({\"label\": \"NAME\", \"pattern\": pattern})\n",
    "\n",
    "for edu in education:\n",
    "    pattern = [{\"LOWER\": edu.lower()}]\n",
    "    patterns.append({\"label\": \"EDUCATION\", \"pattern\": pattern})\n",
    "\n",
    "for cer in certifications:\n",
    "    pattern = [{\"LOWER\": cer.lower()}]\n",
    "    patterns.append({\"label\": \"CERTIFICATIONS\", \"pattern\": pattern})\n",
    "\n",
    "for jr in job_roles:\n",
    "    tokens = jr.split()\n",
    "    pattern = [{\"LOWER\": token.lower()} for token in tokens]\n",
    "    patterns.append({\"label\": \"JOB ROLE\", \"pattern\": pattern})\n",
    "\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "093594e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Scientist JOB ROLE\n",
      "Machine Learning SKILL\n",
      "Machine Learning SKILL\n",
      "Python SKILL\n",
      "SQL SKILL\n",
      "Data Scientist JOB ROLE\n",
      "Data Scientist JOB ROLE\n",
      "Data Scientist JOB ROLE\n",
      "Python SKILL\n",
      "TensorFlow SKILL\n",
      "Machine Learning SKILL\n",
      "Python SKILL\n",
      "Machine Learning SKILL\n",
      "Python SKILL\n",
      "Python SKILL\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "82b8e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    'name': '',\n",
    "    'education': [],\n",
    "    'certifications': [],\n",
    "    'skills': [],\n",
    "    'job_role': [] \n",
    "}\n",
    "\n",
    "skills = set()\n",
    "jr = set()\n",
    "\n",
    "for ent in doc.ents:\n",
    "    label = ent.label_.lower()\n",
    "    if label == 'name':\n",
    "        d['name'] = ent.text.lower()\n",
    "\n",
    "    elif label == 'education':\n",
    "        d['education'].append(ent.text.lower())\n",
    "    elif label == 'job role':\n",
    "        jr.add(ent.text.lower())\n",
    "    elif label == 'certifications':\n",
    "        d['certifications'].append(ent.text.lower())\n",
    "    elif label == 'skill':\n",
    "        skills.add(ent.text.lower())\n",
    "    \n",
    "d['skills'] = skills\n",
    "d['job_role'] = jr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c23319b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '',\n",
       " 'education': [],\n",
       " 'certifications': [],\n",
       " 'skills': {'machine learning', 'python', 'sql', 'tensorflow'},\n",
       " 'job_role': {'data scientist'}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab8b9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
