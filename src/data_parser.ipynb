{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80376095-6bbe-43bd-b351-1c6301204e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 1000 rows, 11 columns\n",
      "Data cleaned: (1000, 11) -> (1000, 11)\n",
      "Removed 0 rows\n",
      "\n",
      "Target Distribution:\n",
      "Target\n",
      "1    812\n",
      "0    188\n",
      "Name: count, dtype: int64\n",
      "Hire Rate: 81.20%\n",
      "\n",
      "==================================================\n",
      "DATASET INFORMATION\n",
      "==================================================\n",
      "\n",
      "Shape: (1000, 12)\n",
      "\n",
      "Columns: ['Resume_ID', 'Name', 'Skills', 'Experience (Years)', 'Education', 'Certifications', 'Job Role', 'Recruiter Decision', 'Salary Expectation ($)', 'Projects Count', 'AI Score (0-100)', 'Target']\n",
      "\n",
      "Missing Values:\n",
      "No missing values\n",
      "\n",
      "Data Types:\n",
      "Resume_ID                  int64\n",
      "Name                      object\n",
      "Skills                    object\n",
      "Experience (Years)         int64\n",
      "Education                 object\n",
      "Certifications            object\n",
      "Job Role                  object\n",
      "Recruiter Decision        object\n",
      "Salary Expectation ($)     int64\n",
      "Projects Count             int64\n",
      "AI Score (0-100)           int64\n",
      "Target                     int64\n",
      "dtype: object\n",
      "\n",
      "Numerical Statistics:\n",
      "         Resume_ID  Experience (Years)  Salary Expectation ($)  \\\n",
      "count  1000.000000         1000.000000             1000.000000   \n",
      "mean    500.500000            4.896000            79994.486000   \n",
      "std     288.819436            3.112695            23048.472549   \n",
      "min       1.000000            0.000000            40085.000000   \n",
      "25%     250.750000            2.000000            60415.750000   \n",
      "50%     500.500000            5.000000            79834.500000   \n",
      "75%     750.250000            8.000000            99583.250000   \n",
      "max    1000.000000           10.000000           119901.000000   \n",
      "\n",
      "       Projects Count  AI Score (0-100)       Target  \n",
      "count      1000.00000       1000.000000  1000.000000  \n",
      "mean          5.13300         83.950000     0.812000  \n",
      "std           3.23137         20.983036     0.390908  \n",
      "min           0.00000         15.000000     0.000000  \n",
      "25%           2.00000         70.000000     1.000000  \n",
      "50%           5.00000        100.000000     1.000000  \n",
      "75%           8.00000        100.000000     1.000000  \n",
      "max          10.00000        100.000000     1.000000  \n",
      "\n",
      "Job Roles:\n",
      "Job Role\n",
      "AI Researcher            257\n",
      "Data Scientist           255\n",
      "Cybersecurity Analyst    255\n",
      "Software Engineer        233\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Education Levels:\n",
      "Education\n",
      "B.Sc      205\n",
      "MBA       202\n",
      "B.Tech    200\n",
      "M.Tech    198\n",
      "PhD       195\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Features shape: (1000, 7)\n",
      "Target shape: (1000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/zsm677xd4j7g9lhh225l86km0000gn/T/ipykernel_6227/4260032161.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.df['Certifications'].fillna('None', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data Parser Module\n",
    "Loads and preprocesses the resume dataset\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "class DataParser:\n",
    "    def __init__(self, filepath: str):\n",
    "        \"\"\"\n",
    "        Initialize the DataParser with dataset filepath\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to the CSV file\n",
    "        \"\"\"\n",
    "        self.filepath = filepath\n",
    "        self.df = None\n",
    "        \n",
    "    def load_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Load the dataset from CSV\"\"\"\n",
    "        self.df = pd.read_csv(self.filepath)\n",
    "        print(f\"Dataset loaded: {self.df.shape[0]} rows, {self.df.shape[1]} columns\")\n",
    "        return self.df\n",
    "    \n",
    "    def clean_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Clean the dataset by handling missing values and duplicates\"\"\"\n",
    "        if self.df is None:\n",
    "            raise ValueError(\"Data not loaded. Call load_data() first.\")\n",
    "        \n",
    "        # Store original shape\n",
    "        original_shape = self.df.shape\n",
    "        \n",
    "        # Handle missing values in Certifications (fill with \"None\")\n",
    "        self.df['Certifications'].fillna('None', inplace=True)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        self.df.drop_duplicates(subset=['Resume_ID'], inplace=True)\n",
    "        \n",
    "        # Remove rows with missing critical information\n",
    "        critical_cols = ['Skills', 'Experience (Years)', 'Education', 'Job Role', 'Recruiter Decision']\n",
    "        self.df.dropna(subset=critical_cols, inplace=True)\n",
    "        \n",
    "        print(f\"Data cleaned: {original_shape} -> {self.df.shape}\")\n",
    "        print(f\"Removed {original_shape[0] - self.df.shape[0]} rows\")\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def encode_target(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Encode the target variable 'Recruiter Decision' as binary\n",
    "        Hire = 1, Reject = 0\n",
    "        \"\"\"\n",
    "        if self.df is None:\n",
    "            raise ValueError(\"Data not loaded. Call load_data() first.\")\n",
    "        \n",
    "        # Create binary target\n",
    "        self.df['Target'] = self.df['Recruiter Decision'].apply(\n",
    "            lambda x: 1 if x == 'Hire' else 0\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nTarget Distribution:\")\n",
    "        print(self.df['Target'].value_counts())\n",
    "        print(f\"Hire Rate: {self.df['Target'].mean():.2%}\")\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def get_data_info(self) -> None:\n",
    "        \"\"\"Print detailed information about the dataset\"\"\"\n",
    "        if self.df is None:\n",
    "            raise ValueError(\"Data not loaded. Call load_data() first.\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"DATASET INFORMATION\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        print(f\"\\nShape: {self.df.shape}\")\n",
    "        print(f\"\\nColumns: {self.df.columns.tolist()}\")\n",
    "        \n",
    "        print(\"\\nMissing Values:\")\n",
    "        missing = self.df.isnull().sum()\n",
    "        print(missing[missing > 0] if missing.sum() > 0 else \"No missing values\")\n",
    "        \n",
    "        print(\"\\nData Types:\")\n",
    "        print(self.df.dtypes)\n",
    "        \n",
    "        print(\"\\nNumerical Statistics:\")\n",
    "        print(self.df.describe())\n",
    "        \n",
    "        print(\"\\nJob Roles:\")\n",
    "        print(self.df['Job Role'].value_counts())\n",
    "        \n",
    "        print(\"\\nEducation Levels:\")\n",
    "        print(self.df['Education'].value_counts())\n",
    "    \n",
    "    def prepare_for_modeling(self) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        Prepare data for model training\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (features_df, target_series)\n",
    "        \"\"\"\n",
    "        if self.df is None:\n",
    "            raise ValueError(\"Data not loaded. Call load_data() first.\")\n",
    "        \n",
    "        if 'Target' not in self.df.columns:\n",
    "            self.encode_target()\n",
    "        \n",
    "        # Select relevant columns for feature engineering\n",
    "        feature_cols = [\n",
    "            'Skills', 'Experience (Years)', 'Education', \n",
    "            'Certifications', 'Job Role', 'Projects Count', 'AI Score (0-100)'\n",
    "        ]\n",
    "        \n",
    "        X = self.df[feature_cols].copy()\n",
    "        y = self.df['Target'].copy()\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    parser = DataParser('../data/raw/AI_RESUME_SCREENING.csv')\n",
    "    \n",
    "    # Load and clean data\n",
    "    df = parser.load_data()\n",
    "    df = parser.clean_data()\n",
    "    df = parser.encode_target()\n",
    "    \n",
    "    # Get info\n",
    "    parser.get_data_info()\n",
    "    \n",
    "    # Prepare for modeling\n",
    "    X, y = parser.prepare_for_modeling()\n",
    "    print(f\"\\nFeatures shape: {X.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6721351-d255-4c6d-bb9a-fe22e955803f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbbc106-706c-429a-adf4-18c01570932e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
